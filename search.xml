<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[第一章 弹桌面的手指]]></title>
      <url>https://selfpoised.github.io/2017/06/09/%E5%9B%9A%E7%8A%AF14029-%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%BC%B9%E6%A1%8C%E9%9D%A2%E7%9A%84%E6%89%8B%E6%8C%87/</url>
      <content type="html"><![CDATA[<p><img src="http://ohz440knb.bkt.clouddn.com/%E5%9B%9A%E7%8A%AF14029chap1.jpg" alt="chapter1"></p>
<p>我们大约是傍晚驱车离开了济南，丰田霸道这种性能极好的四驱越野车闪过一个个城市向青岛疾驰。到了即墨还距青岛有三十公里时，巨大的雨幕突然拉开，接着是电闪雷鸣我们的车像是饺子扔进了锅里在暴雨中似要漂起来。</p>
<p>我们的车穿过暴雨的挤压一直冲到了青岛市区，然后又冲到了青岛有名的香港路上，雨幕下香港路两侧的所有灯光看上去很别致很像海市蜃楼突现。此后的三个小时我们坐在车里沿香港路直抵石老人，从城阳又绕到市南区直到市北区又突入了啤酒街。车里有人说刚接到电话告诉追踪的讯号没有了，有人骂了一声接着有人提议那就休息一下吧。</p>
<p>啤酒街上全是啤酒馆，我们停车的位置右侧是一个酒吧，它的苹果形灯箱非常别致令我的心象是被一只温柔的手轻轻地碰了一下。我说咱们先到酒吧里歇一下再说。</p>
<p>酒吧里边呈现的气氛非常简单又神秘像是从印第安领地那边直接搬过来的，只是桌子都格外的精致，我思忖酒吧老板可能是个个性自由的人。当我们从非常轻且又极清晰的音乐里绕过桌子时，我看到几个人围坐的桌子边上一个女性一手抚摸一个大啤酒杯、一只手纤长的手指在桌面上有节奏的轻弹。在极为柔软的灯光下她清晰的眼神让我止住了脚步，我看见了她。</p>
<p>很多年前我曾经被现在刑法中已取消的罪名判处过无期徒刑，而且在青岛某监狱服刑十五年。据不确定统计，在监狱中有三个人知名度最高：监狱长、女狱医周木还有我。</p>
<p>在我入狱服刑的第二个月时就知道了周木是谁。那是一个星期天我已分配在老残队改造 ， 监区长助理让监区卫生室犯医通知有需要配眼镜的服刑人员集合到狱内医院去验光登记 。 我的眼镜已在入狱第一次挨批斗时摔坏了，我也拄着拐棍一扭一扭地随着其他人下楼到院子里排队集合。在监区院子里带队宋管教见有四、五十人排队，不耐烦地说几年啦也没见过你们谁戴过眼镜，每次一说配眼镜就出来一群近视眼儿，我还不知道你们这群老东西的心思。随后宋管教扫了一眼挑出几个戴过老花镜的老残犯人还有我走了。</p>
<p>到了狱内医院我们在门诊部外边排队，我就听到一块来的几个人小声说半年没见到周木了也不知道她胖了还是瘦了。这几个老残队的犯人在监狱里已服刑多年，有的还是多次入狱服刑。我从他们说话中知道周木的父亲是监狱的前监狱长。前监狱长很似老电影中访寒问暖的老公社书记，曾对老残队犯人很温和并给予过很多照顾。甚至我还听到一个细节，说的是有个老年犯人临终前想对前监狱长说几句话，那天还是小姑娘的周木拎着一饭盒饺子也跟着来了。</p>
<p>周木从小常跟着周监狱长到狱内来玩和老残队一批又一批犯人很熟。老残队有的犯人在监狱里服刑十几年，是看着周木长大的。据老眼昏花的犯人讲，周木小时候每次和周监狱长到狱内来都背着周监狱长偷着给犯人们香烟和糖，这是老残队犯人最念念不忘的。一个已第八次入狱的老犯人告诉我以前监狱放电影时管教家属都可以和犯人一起看只需拉根绳子隔开。</p>
<p>轮到老残队验光时我是排在第一个，但我身后的老羊毛却一屁股把我顶开钻到了前头。我听到屋里有个轻软的声音说老羊毛你怎么又回来了这是第几次了。老羊头嘿嘿笑着问你爹身体可好。</p>
<p>过了会儿我见到了老残队犯人争先恐后要来见的狱医周木，她没戴警帽身着白大褂像美国西部电影中刚把左轮枪扔在桌上的演员。她问我是按原有眼镜配还是重新验光，我告诉她按原来的眼镜配就行。她看见我的简易拐棍后让我坐在椅子上，然后在问答间我看到她用笔做记录是左手，右手在桌面上随意地轻弹着。她对我说在监狱里也没什么书可看还是尽量少戴眼镜养养眼睛。</p>
<p>在随后的日子里我几乎每天都在听老残队的老头们在念叨周木，似乎这是他们可以共同编撰的历史，除此之外就是糊火柴盒及无尽的争吵。</p>
<p>第二次见到周木时是一个清晨，那天管教让我们几个年轻点的人扫狱内的踊道，这条路从监狱大门处一直通到狱内尽头，像是在一块方正的豆腐中间切了一刀。清晨能站在笔直的踊道上面对清朗的阳光对我来说就如在地下埋了一万年的石头在晒太阳。</p>
<p>我所在老残队被封闭在监舍楼的第三层上，由于老残队里神经病或疑似神经病的人太多，在三楼上专门装了一个隔断门并有强壮的犯人把守以防老残队犯人梦游样出来，因而我也很少能长时间地站在阳光下遐想。</p>
<p>就在阳光铺洒下来的早晨，踊道两边的各监区大院里集合点名完毕在唱歌的准备前往生产区劳动的队伍正待出发时，周木从监狱大门走进来了。周木穿过那道令无数犯人绝望的大门时，我在弯腰厥着腚拣垃圾，当我直起腰顺便向监狱大门处遐想性地望去时，看见一个美军样的人出现在我眼中的地平线上：我分辨出那是一个女性身姿，身穿着茄克式警装头戴大檐警帽，帽子稍微向一边倾斜长发覆盖在两肩，她一手插在裤兜里另一只手环抱着几本书，像是才从航空母舰的舰桥上下来向舰首走去。我认出了那个美军样的人就是周木 ， 她正在清晨的阳光下走进监狱里稠厚的气氛中，似乎可以看到她行走时身后留下的空洞。</p>
<p>当周木的长发在她两肩掀动时，各监区出工劳动的队伍正鱼贯跑向踊道。上千的犯人喊着口号从周木对面跑过，口号声变的减弱并混乱起来，像是狂风到了鲜花盛开的峡谷前犹豫不决了，并且那坚硬的跑步声在一刹那如泡沫板样轻质了，所有犯人的目光都如东方不败手里抛出的绣花线缠绕在周木身上。我似乎感到这座男性监狱里有正在溃散的东西向四面褪去。</p>
<p>周木在阳光下明媚的目光很像地中海岸边的树林。后来前威海日报广告部经理现犯人的唐风说那天清晨他看到周木时脑子里马上就想到了地中海。</p>
<p>那天清晨周木身着新式警装走进监狱从我眼前走过时，我正拄着大竹扫帚看她蓬松的长发边缘朦胧的光晕。她似乎认出了我戴的眼镜的来源并且还注意地看了一下，后来当她给我做心理测评时提到眼镜的框架显得沉了些，有机会换个轻质一点的。</p>
<p>从那个清晨见到周木，我曾有过的十分钟宁静转眼间就消失了。那天当周木从我面前走过去后，和我一块在扫垃圾的另几个犯人在不停地评论周木，他们似乎在用男性的态度比较女性且语气有些亢奋，这可能是监狱单一品种生活的反应。问题是在对女性的议论中，有个因强奸罪入狱的家伙过分入迷，语气及内容显示均有流氓色彩，因此被担任监督任务的犯人值班员听到并报告了管教干警。</p>
<p>当晚，在脾气暴躁的宋管教主持下老残队对我们几个流氓开了个批判会，我一点没有申辩与我无关，我确实认为在欧洲男人如果从审美角度说女性的某些部分性感迷人这不是过错 。但这他妈的是在中国某个偏僻地方的监狱，不是在风流的意大利，我忘了环境。然而令人诡异的是在二年后的一个中午，当初连累了我挨批斗并挂上流氓称号的那家伙在一口气吃了八个窝头并还顺利地喝下一碗菜汤后讲他如何在农村的河边及麦地里强奸妇女时竟一头倒在地上气绝了，当时他才二十五岁。</p>
<p>这突如其来的死亡事件被列入我所在监狱的“十大谜”之中，很多年后又被整理出个“十一大谜”，这个谜是关于我的。</p>
<p>江泽民总书记在任时曾代表中国政府签署了一个关于改善监狱囚犯的国际公约，之后中国政府向国际社会发表了《中国政府改造罪犯白皮书》。为配合白皮书的发表，长春纪录电影制片厂到我所在监狱拍摄反映罪犯日常生产学习和生活的纪录片，而我所在的老弱病残犯人集中关押的分监区也是拍摄环节之一，据说还很重要。</p>
<p>按照司法部的要求，监狱要提供的近镜犯人必须是高个、长相顺眼、年轻并要掺杂几个戴眼镜的。关于要戴眼镜的犯人入镜我曾听拍摄组人员告诉我是因为前几年发生的某个事件涉及很多在校生，纪录片中还要着重但暗示性地反映出他们在监狱中的生活状态。</p>
<p>按照司法部的要求，我似乎是更全面的符合标准，因此在初选时即被列入近景人员并且还发给我一份台词让我背熟。我当然知道这意味了什么，于是我拒绝了。后来我知道了有台词的犯人参加拍摄后每人奖励了二十分。而且我还知道了为了显示监狱饮食良好，纪录片中主要的服刑人员是由长影演员扮的，一是他们的气色及精神状态更好二是他们扮服刑人员更可靠。</p>
<p>我呢，在正式拍摄的那天监狱为安全起见监狱长说不能让那帮老残队的人露面，于是我和老残队里那批神经不正常的家伙们被关在仓库一整天。幸好那天我带上了马尔克斯的《霍乱时期的爱情》爬在仓库里过足了眼瘾。</p>
<p>拍摄纪录片结束后不久的一天狱政处长突然出现在老残队，负责老残队的李管教陪着狱政处长站在我所在监舍口向里张望。我当时正在忙着糊火柴盒，就是那种出口的大火柴盒 。 这时已患有老年痴呆症的孙老头正缠着我要吃浆糊，而我为摆脱孙老头的纠缠只好用木条沾了点儿浆糊喂到他的嘴里。孙老头嘴里含着浆糊满意地走了，老羊毛又凑了过来强行要给我讲他在一九四八年当排长时打进文登城后住在地主家和地主老婆发生的故事，条件是换三根香烟。老羊毛把这个故事至少已强行卖给我了三十次，在第二十次时我曾说他再编点否则就卖不出去了，那之后老羊毛再拿他的故事换香烟时又把地主女儿加上了。</p>
<p>老羊毛拿着我给他的香烟走了，我极为厌恶他编那些与地主老婆之间的情色故事，在他的意识中地主家的女性是可以随便糟践的。多年以后我猛然明白了监狱里为什么有如此多关于女性的故事，它竟是延缓监狱里男性们向同性恋者发展的阻滞剂。有人说监狱可以让服刑五年以上的犯人看情色电影，如果谁没有了生理反应即可判断他是环境因素导致的性指向改变。</p>
<p>第二天早晨天下起雨来，我站在窗前向外看铅色的天空沉厚无比紧紧地压在我的目光上 。 监狱的大院里空无一人没有树没有飞乌没有一根草，我的内心在一瞬间又涌出了自杀的意识，而且这个念头像被浆糊粘贴在了脑子里死活也赶不走。我努力向后退想象着自已离开了窗前但却并没有移动一步，我心中又涌起一阵恐慌害怕自己失去控制。我憋住了气用尽全力大感一声瞬间感到自已飘动了一下，我松懈下来了所有的感觉重又出现。</p>
<p>糊了会儿火柴盒值班员叫我去办公室，李管教告诉我狱政处通知我去狱内医院做心理测评。</p>
<p>站在门外我喊了声“报告”，屋内传来请进的允许答复后我走进狱内医院办公室，看到一个很美的女性背对我在给窗台上的花浇水，我认为她从玻璃的反光上看到我被雨淋湿的光头，她伸手从脸盆架上抽了条毛巾并未回头递给我说擦一下头上的雨水并让我坐在办公桌对面的椅子上。我没用她递给我的毛巾，用手在头和脸上抹了几下。</p>
<p>她浇完花转过身来我认出是周木，周木今天穿了件套裙与我两年前在那天清晨看到的婀娜美军大不一样很像一个中学老师。她随意地说这不是自己的办公室这儿显得有些无序，她说监狱里工作的男性警察都很呆板办公室就像车间。她又自嘲地说没有监舍整洁。她又补了一句，当然还是比你们老残队干净。</p>
<p>周木拿起一只瓷杯在水龙头下仔细洗了下在饮水机先接了半杯热水又兑了些凉水走过来放在我面前，我明白了老残队那些犯人们为什么那么喜欢她。</p>
<p>周木坐在我对面，隔着一张桌子的距离让我更清楚地看到了她神情中的所有细节，她不会超过三十岁有些像刚离开芭蕾舞团的样子。我想起自己熟悉的另一个女性她毕业于某师大中文系，因她哥哥在”八三年严打”中死于冤案而成为一个杀手，我曾不相信她纤细的手指能握住金属利器。不过，周木是一个监狱警察她的职业是与犯罪者打交道，她一定自有隐蔽的职业反应。</p>
<p>周木递给我一片口香糖说安全的。我接过口香糖看到包装上没有中文它也许是口香糖也许不是，或者心理测评需要安眠。我把口香糖包装撕开把口香糖放进口中感到有一种奇怪又舒适的香味飘绕在口腔中让人自在。周木说这种口香糖产于巴西由于掺了某种树脂油它所产生的香味很有历史感，有人说嚼着它像是走过了古代。</p>
<p>在我的以往印象中周木是一个在偏僻的山脚下一座监狱中开出的花似乎离繁华的世界很遥远，她说的话却又让我觉得她确实熟悉在太平洋和大西洋之外的世界，有一会儿的时间我还觉得她参观过美军的西点军校。</p>
<p>周木说现在监狱在对服刑人员管理方面增加了一些形式及内容，比如今天要对你做的心理测评就是其中一项。不过它也就是填一摞表，在这之前我们可以随意聊天。我看了下窗外没回答她。</p>
<p>她问你紧张吗？我看她一眼说有点紧张但还舒适。她又问紧张还能舒适？我说紧张是离开了糊火柴的地方不习惯了，舒适是我知道老残队很多人赞赏你而令我内心也坦然。其实我感到要解释清楚这样的感受是挺复杂的，我所指的紧张伴有的舒适是要做某一件刺激性的事儿之前的感觉，可能与肾上腺素分泌过多有关。</p>
<p>我的这种感受是在我少年时期形成的，那时差不多有几年的时间我一直在接受不公开的秘密军事训练。可这里是监狱有可能让别人把自己的心理感受理解为受虐倾向，因为我身上有很多刀疤及枪伤疤痕。</p>
<p>周木笑了，她说自已很熟悉老残队那些老人。在我小的时候就知道他们，那时监狱的警察可以把犯人带回家干活，我听他们讲的很多事就知道了有关命运的一些说法。我没有憎恨他们的原因是以前的社会发生了很多事件并且决定了一些人的命运，正如你到这里来也有决定你命运的其它原因。</p>
<p>周木说的话令我惊讶，因为在监狱对罪犯的改造中理论上认为一个人的犯罪来源于他的主观选择，与任何社会因素无关。</p>
<p>我问她，你刚才说的是一个监狱警察的正式说法吗？她笑着说什么叫正式说法，无论怎么说也是希望人就是人。</p>
<p>我有些信任眼前这个女医生了，她说的话肯定不是从这个社会学来的，社会的统一语言离人很远而且也很冷酷。后来我发现了社会统一语言的影响确实成为监狱内服刑人员对社会更冷漠甚至冷酷的原因之一。而周木随便说的话像是在长期遭受政治轰炸以后的社会文化之外的思维皱褶间有人性那粒清亮的水滴。</p>
<p>周木说我知道一些你的简历当然是从你的档案中看到的，我无权说你是好人还是坏人，我只从自己的工作角度看问题，你们这样的男性除了特种部队喜欢没有一个国家的政府能容忍。周木说的话我母亲也曾对我说过，其中有一半的原因是我母亲在她十五岁时叛逃了家庭偷着参加了革命。</p>
<p>周木说的这话让我差点从自己的木乃伊中跳出来，她很像在兄弟姐妹间说话。我看了周木一秒钟，心想老残队里那些老奸巨滑的行尸走肉们也许就是因为这对她放心的。</p>
<p>她凝视着我说，你能把自己柱拐棍的原因说出来吗？我犹豫了一下回答她是为了在女儿的生日里能见到她而把自己弄伤了。我知道自已的档案中可能会有我当时的说法，另外更重要的原因至少在我没走出监狱前是秘密。在我入狱后的第二年原判法院曾再度到监狱里来问询过我上百个问题，其中也问到周木问的事。我突然对她说，告诉你？</p>
<p>周木沉静地看着我，你已经说出来了。</p>
<p>她问我，你为什么挨了如此多批斗还被多次关禁闭？我谨慎地选择了一个模糊的回答：不适应。她说你倒坦率，对这个环境不适应是正常的，如果哪一天适应了倒会有问题了。你看老残队里的人生活的多自在把监狱当作养老院了，你知道他们三番两次进监狱的原因么。</p>
<p>我沉思了下说，就活着而言，监狱中有可以活下去的条件，从生到死都有人管，除了为自由而活着的其他人要自由干什么。可是我知道另外一些让他们其中一些人从社会再逃回监狱的原因，我认为这个原因没人知道，既使是你从小就接触犯人也不会知道。</p>
<p>她说你告诉我。我真的告诉她了不管她是否吃惊。我说你一定知道曾经农村有地主富农 ， 你也一定填过很多表格其中有家庭出身一项，你填的一定是革命干部。老残队里有几十个人在这一项中写的是地主或富农，这个曾经是阶级斗争对象的地主富农后代中的一些人经历了一些全社会都不知道的事件，这些人曾被反复当作替罪羊判刑，因为很多刑事案件破不了。</p>
<p>周木出现了惊诧的表情。我说我经常帮助管教整理老残队犯人档案发现了这些问题，而且我就和他们生活在一起。当然还有一点其它原因，是我的经历及我有点文化，至少我关注一些事情，我还认为自己生活的国家每一件事都与自己相关。</p>
<p>她的纤长手指又在桌子上弹起来，我们彼此有一会儿没说话。</p>
<p>周木问我，可能你我的年龄差不多，你对自己以往的经历有什么评价，比如说少年阶段和青年阶段？我回答，这两个时期我都有大多数人没有的问题，我不是指心理上的是指我与环境和事件。你可能会知道环境对人的压迫诱惑以及指导，我对这样的背景很敏感，从少年到青年我都被社会性的事件所吸引，这并不分性别。</p>
<p>她说，我小的时候就生活在这个监狱气氛中，我被无数传说的恐怖事件和人物所吸引并以为是真的，再没有谁比我更真实地了解监狱了包括我的父亲。然而我最终发现监狱里关的人只是故事而非是故事的根源，这也是我喜欢马尔克斯写的书的原因，他找到了人所有生活表现的根源，也让我清楚地理解了神秘。周木说，没有什么是神秘的只有什么是秘密的。你也是这样，是秘密给了你压力，当然放弃了秘密有时会受到惩罚，所以几乎每个人都会这么做。</p>
<p>她看我一眼笑了说，我也有无数秘密，就是因为这个原因才有了性格上令人迷惑的色彩 。 我也笑了，我理解了她说的性格色彩，我认为她使用了一个非常清晰的词就是色彩，这是真正迷惑人的地方。而我没有顺着她的话去接近不能接近的地方，我知道这是监狱一但触及到了什么会有危险。</p>
<p>我说你说的很对，如果这不是在监狱里我真愿意让你成为一个观览者了解我的经历。我并不是因为你是警察而把我们彼此可以贯通的地方堵住，我当然也知道这等于堵住了我可以走向轻松的方向。可是很多事情是关联的而且有连锁反应，一但触及一点就会导致一个崩溃的结果。</p>
<p>周木的目光变的尖锐了，她对我说你在积攒的东西会伤及到你，很多的东西是有惯性的 。</p>
<p>她的手指开始在桌面上连续地弹跳起来，我仔细盯住她弹动的手指感到它跳动的很自然 ， 这一观察让我自己也轻松了许多。几年后监狱里有一个犯人未遂暴动事件涉及到我，监狱方怀疑我暗中参与了策划。在禁闭室里我想到了周木和我的这次谈话，她不仅是那些老残病犯人喜欢的人，她还了解被关到监狱中的所有男性，她对我也暗指了某个结果而且她告诉了我。对此我有些惭愧，我那时面对的确实只是一个女性而不是警察。</p>
<p>周木问我，你多久洗一次衣服？我告诉她可能半个月洗一次。她问为什么这么长时间才换洗衣服？我说自己对这件事没在意。我没告诉她有一次在院子里晒太阳时我曾从自己的胶鞋里倒出八十多个虱子。世界上没有人知道我在和周木交谈时穿着从衣袖到衣襟都沾满了浆糊的囚服而且囚服还散发着浓郁的酸味儿。</p>
<p>这次心理测评我没填什么表格，周木说填那些表对我说明不了什么。在我将要离开时周木让药房的犯人送来一盒藿香正气水给我，她说夏天容易腹泻。我看她一眼说谢谢你。我说的极为郑重，在以后的服刑生活中我再没对任何人这样郑重的表达过谢意。</p>
<p>在我柱着拐杖走向门口时看到了她胸前衣裳的印花中别着一个苹果样的胸饰，在此之前我没有向那个方向看过。</p>
<p>回到老残队组长刘聋子试探地问我干什么去了，老残队的库存们一致认为我是个怪物他们对我干什么很好奇。当他们看见我带回来的一纸盒藿香正气水后个个都露出了抢劫犯的表情，而我无异于一个成功干了件走私勾当的家伙。在监狱里藿香正气水是合法的白酒它的液体部分是酒精，谁能弄到它无疑是弄到了茅台。我把藿香正气水分给大家说这是上帝的女儿周木托我带来的。</p>
<p>那之后老残队搬到狱内一个有平房的院子里去了，我和上百个老弱病残犯人被密封在只有下午阳光才能掠过的监狱深处不仅糊火柴盒还剥花生，监狱认为老残队的犯人大多没几颗牙花生损耗不大。然而监狱这样的分析等于救了我，花生的营养恰到好处地弥补了我营养不良的身体让我又能够在困境中挣扎着活下去。</p>
<p>又过了两年，在这期间我无数次想到过周木。想到她的原因是我一点点发现了她能轻易地洞察到我以及这座关押着数千男性的监狱内的所有隐秘，因此她吸引了我正如那些老犯人是如此热爱她一样。</p>
<p>周木最后留给我的信息是有一天她托狱内医院一个警官医生带给我一包书而且都是我渴望读到的书。送书的警官医生告诉我周木已调离监狱到青岛去工作了。当我知道这些后我感自己的内心潮湿了很长一段时间，我说不出这是一个友人还是因想起她就能看到阴雨天也充满阳光的人走远了。</p>
<p>我一直坐在灯光较暗的地方注视着周木在和她的朋友们讨论，她的手指灵巧地从桌面弹跳到啤酒杯上，又再从啤酒杯上弹回到桌面。她有时因别人说的话发出惊讶的笑声有时又是嘲弄的笑声，其间她有时向我坐的地方发来一瞥，她看到的是我模糊的面孔。我躲避了她能认出我来的所有光线，因为她一但认出我后我不知说什么。</p>
<p>我站起身对其他人说走吧不追了。我的同伴不解地盯住我不明白我做的决定。我们在追一个私人侦探公司的人，他用窃听和偷拍让另一个人受到冤屈，我们要把这个恶棍抓到交给警方。我告诉大家有其它办法。</p>
<p>在吧台我向侍应生周木是否常来，侍应生告诉我她是这间叫苹果酒吧的老板。我再回头向周木坐的方向望了一眼，心里想她现在是多么自由。</p>
<pre><code>2015·7·15写于烟台A
</code></pre>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[build h2database source code under intellij idea]]></title>
      <url>https://selfpoised.github.io/2017/03/03/intellij%20build/</url>
      <content type="html"><![CDATA[<h3 id="pom-xml"><a href="#pom-xml" class="headerlink" title="pom.xml"></a>pom.xml</h3><p>h2代码并未直接使用mvn编译，而是使用了mvnw。并且其目标码为java1.6，而其mvn又依赖1.7。为了解决这个问题其使用了maven-toolchains-plugin：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">&lt;!-- Maven requires at least JRE 1.7 but we want to build with JDK 1.6 --&gt;</div><div class="line">      &lt;plugin&gt;</div><div class="line">        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;maven-toolchains-plugin&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;1.1&lt;/version&gt;</div><div class="line">        &lt;executions&gt;</div><div class="line">          &lt;execution&gt;</div><div class="line">            &lt;goals&gt;</div><div class="line">              &lt;goal&gt;toolchain&lt;/goal&gt;</div><div class="line">            &lt;/goals&gt;</div><div class="line">          &lt;/execution&gt;</div><div class="line">        &lt;/executions&gt;</div><div class="line">        &lt;configuration&gt;</div><div class="line">          &lt;toolchains&gt;</div><div class="line">            &lt;jdk&gt;</div><div class="line">              &lt;version&gt;1.6&lt;/version&gt;</div><div class="line">            &lt;/jdk&gt;</div><div class="line">          &lt;/toolchains&gt;</div><div class="line">        &lt;/configuration&gt;</div><div class="line">      &lt;/plugin&gt;</div></pre></td></tr></table></figure></p>
<p>此外，为了检查代码中没有使用jdk1.6之外的东西，又用了如下插件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">&lt;!-- Make sure we are not using anything outside JDK 1.6 --&gt;</div><div class="line">      &lt;plugin&gt;</div><div class="line">        &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;animal-sniffer-maven-plugin&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;1.15&lt;/version&gt;</div><div class="line">        &lt;executions&gt;</div><div class="line">          &lt;execution&gt;</div><div class="line">            &lt;id&gt;check-java-api&lt;/id&gt;</div><div class="line">            &lt;phase&gt;test&lt;/phase&gt;</div><div class="line">            &lt;goals&gt;</div><div class="line">              &lt;goal&gt;check&lt;/goal&gt;</div><div class="line">            &lt;/goals&gt;</div><div class="line">          &lt;/execution&gt;</div><div class="line">        &lt;/executions&gt;</div><div class="line">        &lt;configuration&gt;</div><div class="line">          &lt;signature&gt;</div><div class="line">            &lt;groupId&gt;org.codehaus.mojo.signature&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;java16&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;1.1&lt;/version&gt;</div><div class="line">          &lt;/signature&gt;</div><div class="line">        &lt;/configuration&gt;</div><div class="line">      &lt;/plugin&gt;</div></pre></td></tr></table></figure></p>
<p>仅为学习和调试源码的情况下，可以将上述两个插件去掉，避免编译错误。</p>
<h3 id="idea-配置"><a href="#idea-配置" class="headerlink" title="idea 配置"></a>idea 配置</h3><p>1.添加依赖库<br><img src="http://ohz440knb.bkt.clouddn.com/h2-buildQQ%E5%9B%BE%E7%89%8720170303165203.png" alt="h2依赖库"></p>
<p>2.设置文件路径<br><img src="http://ohz440knb.bkt.clouddn.com/h2-buildQQ%E5%9B%BE%E7%89%8720170303165232.png" alt="路径设置"></p>
<p>特别注意：h2/src/tools要设置在”Test Source Folders”下面，否则会有文件找不到import</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka offsets management in spark streaming]]></title>
      <url>https://selfpoised.github.io/2016/12/03/kafka%20offsets%20management/</url>
      <content type="html"><![CDATA[<p>kafka direct stream的出现，提高了与spark的适配能力与灵活性，可以精确实现一次性消费语义，<br>但是需要用户自行管理offsets。早期版本的offset是存储在zookeeper里面的，但据说对于大的消费场景来说，zookeeper的写性能就成了瓶颈，于是新的版本推荐把索引写入kafka内部队列：__consumer_offsets。</p>
<p>那么，怎么读写kafka offsets呢？如何指定zookeeper或者__consumer_offsets呢？<br>答案就在OffsetCommitRequest和OffsetFetchRequest里。</p>
<h4 id="OffsetFetchRequest-and-OffsetCommitRequest"><a href="#OffsetFetchRequest-and-OffsetCommitRequest" class="headerlink" title="OffsetFetchRequest and OffsetCommitRequest"></a>OffsetFetchRequest and OffsetCommitRequest</h4><p><strong>OffsetFetchRequest</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">case class OffsetFetchRequest(groupId: String,</div><div class="line">                              requestInfo: Seq[TopicAndPartition],</div><div class="line">                              versionId: Short = OffsetFetchRequest.CurrentVersion,</div><div class="line">                              correlationId: Int = 0,</div><div class="line">                              clientId: String = OffsetFetchRequest.DefaultClientId)</div></pre></td></tr></table></figure></p>
<p><strong>OffsetCommitRequest</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">case class OffsetCommitRequest(groupId: String,</div><div class="line">                requestInfo: immutable.Map[TopicAndPartition, OffsetAndMetadata],</div><div class="line">                versionId: Short = OffsetCommitRequest.CurrentVersion,</div><div class="line">                correlationId: Int = 0,</div><div class="line">                clientId: String = OffsetCommitRequest.DefaultClientId,</div><div class="line">                groupGenerationId: Int = org.apache.kafka.common.requests.OffsetCommitRequest.DEFAULT_GENERATION_ID,</div><div class="line">                memberId: String =  org.apache.kafka.common.requests.OffsetCommitRequest.DEFAULT_MEMBER_ID,</div><div class="line">                retentionMs: Long = org.apache.kafka.common.requests.OffsetCommitRequest.DEFAULT_RETENTION_TIME)</div></pre></td></tr></table></figure></p>
<p>versionId为0时指向zookeeper，大于0时则指向__consumer_offsets。</p>
<p>如何使用这两个类，可以参考：<a href="https://cwiki.apache.org/confluence/display/KAFKA/Committing+and+fetching+consumer+offsets+in+Kafka" target="_blank" rel="external">Committing and fetching consumer offsets in Kafka</a></p>
<hr>
<h4 id="KafkaCluster"><a href="#KafkaCluster" class="headerlink" title="KafkaCluster"></a>KafkaCluster</h4><p>在spark里面，如果直接使用上面两个类，显然不太方便，于是就有了KafkaCluster，是为了方便spark操作kafka cluster的封装。reference: <a href="https://github.com/apache/spark/blob/master/external/kafka-0-8/src/main/scala/org/apache/spark/streaming/kafka/KafkaCluster.scala" target="_blank" rel="external">org/apache/spark/streaming/kafka/KafkaCluster.scala</a></p>
<p>提供broker.list等参数即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">class KafkaCluster(val kafkaParams: Map[String, String]) extends Serializable</div></pre></td></tr></table></figure></p>
<p>主要函数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">def getConsumerOffsets(</div><div class="line">      groupId: String,</div><div class="line">      topicAndPartitions: Set[TopicAndPartition],</div><div class="line">      consumerApiVersion: Short</div><div class="line">    ): Either[Err, Map[TopicAndPartition, Long]]</div><div class="line"></div><div class="line">def setConsumerOffsets(</div><div class="line">      groupId: String,</div><div class="line">      offsets: Map[TopicAndPartition, Long],</div><div class="line">      consumerApiVersion: Short</div><div class="line">    ): Either[Err, Map[TopicAndPartition, Short]]</div><div class="line"></div><div class="line">def getPartitions(topics: Set[String]): Either[Err, Set[TopicAndPartition]]</div><div class="line"></div><div class="line">def getLatestLeaderOffsets(</div><div class="line">      topicAndPartitions: Set[TopicAndPartition]</div><div class="line">    ): Either[Err, Map[TopicAndPartition, LeaderOffset]]</div><div class="line">......</div><div class="line">......</div></pre></td></tr></table></figure></p>
<p>getConsumerOffsets与setConsumerOffsets便是offsets的读写函数，consumerApiVersion为0时，其存取媒介为zookeeper，大于0时为__consumer_offsets。</p>
<hr>
<h4 id="spark-streaming自动更新offsets"><a href="#spark-streaming自动更新offsets" class="headerlink" title="spark streaming自动更新offsets"></a>spark streaming自动更新offsets</h4><p>注册streamingContext监听事件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">StreamingContext.addStreamingListener(new StreamingListener())</div></pre></td></tr></table></figure></p>
<p>在StreamingListener里不同事件位置实现offsets更新：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">trait StreamingListener &#123;</div><div class="line"></div><div class="line">  /** Called when a receiver has been started */</div><div class="line">  def onReceiverStarted(receiverStarted: StreamingListenerReceiverStarted) &#123; &#125;</div><div class="line"></div><div class="line">  /** Called when a receiver has reported an error */</div><div class="line">  def onReceiverError(receiverError: StreamingListenerReceiverError) &#123; &#125;</div><div class="line"></div><div class="line">  /** Called when a receiver has been stopped */</div><div class="line">  def onReceiverStopped(receiverStopped: StreamingListenerReceiverStopped) &#123; &#125;</div><div class="line"></div><div class="line">  /** Called when a batch of jobs has been submitted for processing. */</div><div class="line">  def onBatchSubmitted(batchSubmitted: StreamingListenerBatchSubmitted) &#123; &#125;</div><div class="line"></div><div class="line">  /** Called when processing of a batch of jobs has started.  */</div><div class="line">  def onBatchStarted(batchStarted: StreamingListenerBatchStarted) &#123; &#125;</div><div class="line"></div><div class="line">  /** Called when processing of a batch of jobs has completed. */</div><div class="line">  def onBatchCompleted(batchCompleted: StreamingListenerBatchCompleted) &#123; &#125;</div><div class="line"></div><div class="line">  /** Called when processing of a job of a batch has started. */</div><div class="line">  def onOutputOperationStarted(</div><div class="line">      outputOperationStarted: StreamingListenerOutputOperationStarted) &#123; &#125;</div><div class="line"></div><div class="line">  /** Called when processing of a job of a batch has completed. */</div><div class="line">  def onOutputOperationCompleted(</div><div class="line">      outputOperationCompleted: StreamingListenerOutputOperationCompleted) &#123; &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<hr>
<p><img src="http://ohz440knb.bkt.clouddn.com/kafka%20schema15338474_677916559048913_6357551582430625792_n.jpg" alt="lebanon tastes"></p>
<hr>
<h4 id="一个基于KafkaCluster的完整offsets操作实现"><a href="#一个基于KafkaCluster的完整offsets操作实现" class="headerlink" title="一个基于KafkaCluster的完整offsets操作实现"></a>一个基于KafkaCluster的完整offsets操作实现</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div></pre></td><td class="code"><pre><div class="line">import kafka.common.TopicAndPartition</div><div class="line">import kafka.message.MessageAndMetadata</div><div class="line">import kafka.serializer.Decoder</div><div class="line">import org.apache.log4j.Logger</div><div class="line">import org.apache.spark.SparkException</div><div class="line">import org.apache.spark.rdd.RDD</div><div class="line">import org.apache.spark.streaming.StreamingContext</div><div class="line">import org.apache.spark.streaming.dstream.InputDStream</div><div class="line">import org.apache.spark.streaming.kafka.KafkaCluster.LeaderOffset</div><div class="line">import org.apache.spark.streaming.kafka.&#123;HasOffsetRanges, KafkaCluster, KafkaUtils&#125;</div><div class="line"></div><div class="line">import scala.reflect.ClassTag</div><div class="line"></div><div class="line">/**</div><div class="line">  * KafkaCluster encapsulation, provides mainly offset management methods</div><div class="line">  *</div><div class="line">  * offsetSavingMode == KafkaEnums.zookeeper means offset saved in zk</div><div class="line">  * offsetSavingMode == KafkaEnums.kafka means offset saved in kafka</div><div class="line">  */</div><div class="line">class KafkaManager(val kafkaParams: Map[String, String], val offsetSavingMode: KafkaEnums) &#123;</div><div class="line">  private val kc = new KafkaCluster(kafkaParams)</div><div class="line"></div><div class="line">  /**</div><div class="line">    * consumerApiVersion == 0 means offset saved in zk</div><div class="line">    * consumerApiVersion == 1 means offset saved in kafka</div><div class="line">    */</div><div class="line">  def consumerApiVersion = if(offsetSavingMode == KafkaEnums.kafka) &#123;1.toShort&#125; else &#123;0.toShort&#125;</div><div class="line"></div><div class="line">  /**</div><div class="line">    * 由于kafka本身的消息留存机制，用户保存的offset可能与队列实际</div><div class="line">    * 情况不一致。该函数对用户保存offset进行合理重置</div><div class="line">    *</div><div class="line">    */</div><div class="line">  private def setOrUpdateOffsets(topics: Set[String], groupId: String): Unit = &#123;</div><div class="line">    topics.foreach(topic =&gt; &#123;</div><div class="line">      val partitionsE = kc.getPartitions(Set(topic))</div><div class="line">      if (partitionsE.isLeft)&#123;</div><div class="line">        val err = s&quot;get kafka partition failed: $&#123;partitionsE.left.get&#125; for topics &quot; + topics</div><div class="line">        logger.error(err)</div><div class="line">        throw new SparkException(err)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      val partitions = partitionsE.right.get</div><div class="line">      val consumerOffsetsE = kc.getConsumerOffsets(groupId, partitions, consumerApiVersion)</div><div class="line">      // 若某个groupid首次消费，则没有offset信息，会报错，从头开始读</div><div class="line">      logger.warn(&quot;consumerApiVersion: &quot; + consumerApiVersion)</div><div class="line">      // offset存储媒介为zk，此处isLeft为true，表示未曾消费过</div><div class="line">      // 存储媒介为kafka时，此处是有右值的，但是其offset为-1，小于earliestLeaderOffset，</div><div class="line">      // 因而会被重置为0，即从头开始消费</div><div class="line">      if (consumerOffsetsE.isLeft)&#123; // 未曾消费过</div><div class="line">        val reset = kafkaParams.get(&quot;auto.offset.reset&quot;).map(_.toLowerCase)</div><div class="line">        var leaderOffsets: Map[TopicAndPartition, LeaderOffset] = null</div><div class="line"></div><div class="line">        if (reset == Some(&quot;smallest&quot;)) &#123;// 从头消费</div><div class="line">          val leaderOffsetsE = kc.getEarliestLeaderOffsets(partitions)</div><div class="line">          if (leaderOffsetsE.isLeft)&#123;</div><div class="line">            val err = s&quot;get earliest leader offsets failed: $&#123;leaderOffsetsE.left.get&#125; for partitions &quot; + partitions</div><div class="line">            logger.error(err)</div><div class="line">            throw new SparkException(err)</div><div class="line">          &#125;</div><div class="line">          leaderOffsets = leaderOffsetsE.right.get</div><div class="line">        &#125; else &#123; // 从最新offset处消费</div><div class="line">          val leaderOffsetsE = kc.getLatestLeaderOffsets(partitions)</div><div class="line">          if (leaderOffsetsE.isLeft)&#123;</div><div class="line">            val err = s&quot;get latest leader offsets failed: $&#123;leaderOffsetsE.left.get&#125; for partitions &quot; + partitions</div><div class="line">            logger.error(err)</div><div class="line">            throw new SparkException(err)</div><div class="line">          &#125;</div><div class="line">          leaderOffsets = leaderOffsetsE.right.get</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        val offsets = leaderOffsets.map &#123;case (tp, offset) =&gt; (tp, offset.offset)&#125;</div><div class="line">        kc.setConsumerOffsets(groupId, offsets, consumerApiVersion)</div><div class="line">      &#125;else&#123; // 消费过</div><div class="line">        /**</div><div class="line">          * 如果streaming程序执行的时候出现kafka.common.OffsetOutOfRangeException，</div><div class="line">          * 说明保存的offsets已经过时了，即kafka的定时清理策略已经将包含该offsets的文件删除。</div><div class="line">          * 针对这种情况，只要判断一下保存的consumerOffsets和earliestLeaderOffsets的大小，</div><div class="line">          * 如果consumerOffsets比earliestLeaderOffsets还小的话，说明consumerOffsets已过时,</div><div class="line">          * 这时把consumerOffsets更新为earliestLeaderOffsets</div><div class="line">          */</div><div class="line">        val earliestLeaderOffsetsE = kc.getEarliestLeaderOffsets(partitions)</div><div class="line">        if (earliestLeaderOffsetsE.isLeft)&#123;</div><div class="line">          val err = s&quot;get earliest leader offsets failed: $&#123;earliestLeaderOffsetsE.left.get&#125; for partitions &quot; + partitions</div><div class="line">          logger.error(err)</div><div class="line">          throw new SparkException(err)</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        val earliestLeaderOffsets = earliestLeaderOffsetsE.right.get</div><div class="line">        val consumerOffsets = consumerOffsetsE.right.get</div><div class="line">        // 可能只是部分分区consumerOffsets过时，</div><div class="line">        // 所以只更新过时分区的consumerOffsets为earliestLeaderOffsets</div><div class="line">        var offsets: Map[TopicAndPartition, Long] = Map()</div><div class="line">        consumerOffsets.foreach(&#123;</div><div class="line">          case(tp, cOffset) =&gt;</div><div class="line">          &#123;</div><div class="line">            val earliestLeaderOffset = earliestLeaderOffsets(tp).offset</div><div class="line">            if (cOffset &lt; earliestLeaderOffset) &#123;</div><div class="line">              logger.warn(&quot;consumer group:&quot; + groupId + &quot;,topic:&quot; + tp.topic +</div><div class="line">                &quot;,partition:&quot; + tp.partition + &quot; offsets已经过时，更新为&quot; + earliestLeaderOffset)</div><div class="line"></div><div class="line">              offsets += (tp -&gt; earliestLeaderOffset)</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;)</div><div class="line"></div><div class="line">        if (!offsets.isEmpty) &#123;</div><div class="line">          kc.setConsumerOffsets(groupId, offsets, consumerApiVersion)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  def updateOffsets(rdd: RDD[(Object, Object, String)]) : Unit = &#123;</div><div class="line">    val groupId = kafkaParams.get(&quot;group.id&quot;).get</div><div class="line">    val offsetsList = rdd.asInstanceOf[HasOffsetRanges].offsetRanges</div><div class="line">    for (offsets &lt;- offsetsList) &#123;</div><div class="line">      val topicAndPartition = TopicAndPartition(offsets.topic, offsets.partition)</div><div class="line">      val o = kc.setConsumerOffsets(groupId, Map((topicAndPartition, offsets.untilOffset)), consumerApiVersion)</div><div class="line">      if (o.isLeft) &#123;</div><div class="line">        logger.error(s&quot;Error updating the offset to Kafka cluster: $&#123;o.left.get&#125; for group &quot; + groupId)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  def updateOffsets(offset: Map[TopicAndPartition, Long]) : Unit = &#123;</div><div class="line">    val groupId = kafkaParams.get(&quot;group.id&quot;).get</div><div class="line">    val o = kc.setConsumerOffsets(groupId, offset, consumerApiVersion)</div><div class="line">    if (o.isLeft) &#123;</div><div class="line">      logger.error(s&quot;Error updating the offset to Kafka cluster: $&#123;o.left.get&#125; for group &quot; + groupId + &quot; &quot; + offset)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  def restoreOffsets(topics: Set[String]): Map[TopicAndPartition, Long] =&#123;</div><div class="line">    val groupId = kafkaParams.get(&quot;group.id&quot;).get</div><div class="line"></div><div class="line">    // 读取offsets前先根据实际情况更新offsets</div><div class="line">    setOrUpdateOffsets(topics, groupId)</div><div class="line"></div><div class="line">    val partitionsE = kc.getPartitions(topics)</div><div class="line">    if (partitionsE.isLeft)&#123;</div><div class="line">      val err = s&quot;get kafka partition failed: $&#123;partitionsE.left.get&#125; for topics &quot; + topics</div><div class="line">      logger.error(err)</div><div class="line">      throw new SparkException(err)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    val partitions = partitionsE.right.get</div><div class="line">    val consumerOffsetsE = kc.getConsumerOffsets(groupId, partitions, consumerApiVersion)</div><div class="line">    if (consumerOffsetsE.isLeft)&#123;</div><div class="line">      val err = s&quot;get kafka consumer offsets failed: $&#123;consumerOffsetsE.left.get&#125; for group &quot; + groupId</div><div class="line">      logger.error(err)</div><div class="line">      throw new SparkException(err)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    consumerOffsetsE.right.get</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka schema of the Confluent platform]]></title>
      <url>https://selfpoised.github.io/2016/12/03/kafka%20schema/</url>
      <content type="html"><![CDATA[<p>在消费kafka消息的时候，可能会有疑问，消息里是否自带schema，schema是如何在反序列化<br>消息的时候起作用的。实际上在conflument平台上，kafka消息格式如下：</p>
<table>
<thead>
<tr>
<th>Bytes</th>
<th>Area</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Magic Byte</td>
<td>Confluent serialization format version number; currently always 0.</td>
</tr>
<tr>
<td>1-4</td>
<td>Schema ID</td>
<td>4-byte schema ID as returned by the Schema Registry</td>
</tr>
<tr>
<td>5</td>
<td>Data</td>
<td>Avro serialized data in Avro’s binary encoding. The only exception is raw bytes, which will be written directly without any special Avro encoding.</td>
</tr>
</tbody>
</table>
<hr>
<h4 id="生产端"><a href="#生产端" class="headerlink" title="生产端"></a>生产端</h4><p>encoder获取schema并且向schema registry请求一个schema id，若已存在则直接返回，若没有则新产生一个并注册<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">import org.apache.avro.Schema;</div><div class="line">import org.apache.avro.generic.GenericData;</div><div class="line">import org.apache.avro.generic.GenericRecord;</div><div class="line">import org.apache.kafka.clients.producer.KafkaProducer;</div><div class="line">import org.apache.kafka.clients.producer.ProducerConfig;</div><div class="line">import org.apache.kafka.clients.producer.ProducerRecord;</div><div class="line">import java.util.Properties;</div><div class="line"></div><div class="line">Properties props = new Properties();</div><div class="line">props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);</div><div class="line">props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,</div><div class="line">          io.confluent.kafka.serializers.KafkaAvroSerializer.class);</div><div class="line">props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,</div><div class="line">          io.confluent.kafka.serializers.KafkaAvroSerializer.class);</div><div class="line">props.put(&quot;schema.registry.url&quot;, &quot;http://localhost:8081&quot;);</div><div class="line">KafkaProducer producer = new KafkaProducer(props);</div><div class="line"></div><div class="line">String key = &quot;key1&quot;;</div><div class="line">String userSchema = &quot;&#123;\&quot;type\&quot;:\&quot;record\&quot;,&quot; +</div><div class="line">                    &quot;\&quot;name\&quot;:\&quot;myrecord\&quot;,&quot; +</div><div class="line">                    &quot;\&quot;fields\&quot;:[&#123;\&quot;name\&quot;:\&quot;f1\&quot;,\&quot;type\&quot;:\&quot;string\&quot;&#125;]&#125;&quot;;</div><div class="line">Schema.Parser parser = new Schema.Parser();</div><div class="line">Schema schema = parser.parse(userSchema);</div><div class="line">GenericRecord avroRecord = new GenericData.Record(schema);</div><div class="line">avroRecord.put(&quot;f1&quot;, &quot;value1&quot;);</div><div class="line"></div><div class="line">ProducerRecord&lt;Object, Object&gt; record = new ProducerRecord&lt;&gt;(&quot;topic1&quot;, key, avroRecord);</div><div class="line">try &#123;</div><div class="line">  producer.send(record);</div><div class="line">&#125; catch(SerializationException e) &#123;</div><div class="line">  // may need to do something with it</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<hr>
<p><img src="http://ohz440knb.bkt.clouddn.com/kafka%20schema14547664_340090316367092_266735473584504832_n.jpg" alt="indian peacock"></p>
<hr>
<h4 id="消费端"><a href="#消费端" class="headerlink" title="消费端"></a>消费端</h4><p>根据shema id从schema registry请求schema，并且在本地缓存<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">import org.apache.avro.generic.IndexedRecord;</div><div class="line">import kafka.consumer.ConsumerConfig;</div><div class="line">import kafka.consumer.ConsumerIterator;</div><div class="line">import kafka.consumer.KafkaStream;</div><div class="line">import kafka.javaapi.consumer.ConsumerConnector;</div><div class="line">import io.confluent.kafka.serializers.KafkaAvroDecoder;</div><div class="line">import kafka.message.MessageAndMetadata;</div><div class="line">import kafka.utils.VerifiableProperties;</div><div class="line">import org.apache.kafka.common.errors.SerializationException;</div><div class="line">import java.util.*;</div><div class="line"></div><div class="line">Properties props = new Properties();</div><div class="line">props.put(&quot;zookeeper.connect&quot;, &quot;localhost:2181&quot;);</div><div class="line">props.put(&quot;group.id&quot;, &quot;group1&quot;);</div><div class="line">props.put(&quot;schema.registry.url&quot;, &quot;http://localhost:8081&quot;);</div><div class="line"></div><div class="line">String topic = &quot;topic1&quot;;</div><div class="line">Map&lt;String, Integer&gt; topicCountMap = new HashMap&lt;&gt;();</div><div class="line">topicCountMap.put(topic, new Integer(1));</div><div class="line"></div><div class="line">VerifiableProperties vProps = new VerifiableProperties(props);</div><div class="line">KafkaAvroDecoder keyDecoder = new KafkaAvroDecoder(vProps);</div><div class="line">KafkaAvroDecoder valueDecoder = new KafkaAvroDecoder(vProps);</div><div class="line"></div><div class="line">ConsumerConnector consumer = kafka.consumer.Consumer.createJavaConsumerConnector(new ConsumerConfig(props));</div><div class="line"></div><div class="line">Map&lt;String, List&lt;KafkaStream&lt;Object, Object&gt;&gt;&gt; consumerMap = consumer.createMessageStreams(</div><div class="line">    topicCountMap, keyDecoder, valueDecoder);</div><div class="line">KafkaStream stream = consumerMap.get(topic).get(0);</div><div class="line">ConsumerIterator it = stream.iterator();</div><div class="line">while (it.hasNext()) &#123;</div><div class="line">  MessageAndMetadata messageAndMetadata = it.next();</div><div class="line">  try &#123;</div><div class="line">    String key = (String) messageAndMetadata.key();</div><div class="line">    IndexedRecord value = (IndexedRecord) messageAndMetadata.message();</div><div class="line"></div><div class="line">    ...</div><div class="line">  &#125; catch(SerializationException e) &#123;</div><div class="line">    // may need to do something with it</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<hr>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a href="http://stackoverflow.com/questions/31204201/apache-kafka-with-avro-and-schema-repo-where-in-the-message-does-the-schema-id" target="_blank" rel="external">Apache Kafka with Avro and Schema Repo - where in the message does the schema Id go?</a><br><a href="http://docs.confluent.io/3.1.1/schema-registry/docs/serializer-formatter.html" target="_blank" rel="external">Serializer and Formatter</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Hello Strangers]]></title>
      <url>https://selfpoised.github.io/2016/12/03/hello-strangers/</url>
      <content type="html"><![CDATA[<p>Welcome to my personal blog, more to come later!</p>
]]></content>
    </entry>
    
  
  
</search>
